---
title: "Report"
author: "Shreysa Sharma, Jashangeet Singh"
date: "10/25/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

Code Repository: https://github.ccs.neu.edu/pdpmr-f17/a6-jashangeet-shreysa.git

#### Specifications of host execution Environment
Attribute                         | Value
----------------------------------|-------------------------------
Java Version                      | 1.8.0_102
Java(TM) SE Runtime Environment   | (build 1.8.0_102-b14)
Java HotSpot(TM) 64-Bit Server VM | (build 25.102-b14, mixed mode)
Model Identifier                  |	MacBookPro11,2
Processor Name                    |	Intel Core i7
Processor Speed                   |	2.2 GHz
Number of Processors              |	1
Total Number of Cores             |	4
L2 Cache (per Core)               |	256 KB
L3 Cache                          |	6 MB
Memory                            | 16 GB

### Summary of the design of evaluated program

The implementation involves reading the data and putting it in SparkContext. 

#### performance Analysis

```{r}
library(ggplot2)
spark_run_local<-read.csv("output/spark_run.csv")
knitr::kable(spark_run_local)
```

The above table represents the total time taken and total average time of 10 runs of Scala job in seconds. Each run takes about  minutes to finish. These values are for the subset on the assignment page on the local machine.

```{r}
library(ggplot2)
spark_run_local_big<-read.csv("output/spark_run_big.csv")
knitr::kable(spark_run_local_big)
```

The above table represents the total time taken and total average time of 10 runs of Scala job in seconds. Each run takes about  minutes to finish. These values are for the full dataset on the local machine.

```{r}
library(ggplot2)
spark_run_emr<-read.csv("output/spark_run_emr.csv")
knitr::kable(spark_run_emr)
```

The above table represents the total time taken by Scala job in seconds. These values are for the subset on the assignment page on EMR.

```{r}
library(ggplot2)
spark_run_big_emr<-read.csv("output/spark_run_big_emr.csv")
knitr::kable(spark_run_big_emr)
```

The above table represents the total time taken by Scala job in seconds. These values are for the full dataset on EMR.


## Data Analysis

####Assumptions

for loudness of song, the closer the loudness score to 0 in negative, the louder the song. If value is 0, then it is an invalid entry
for longness of song, the duration should be greater than 0, the larger the value, longer is the song
for fastness of song, the larger the value of tempo, the faster is the song
for artist familiarity, song hottness, artist hottness, the higher the value from 0, the more familiarity score. If value is 0, record is invalid

For the bigger dataset 
number of distinct songs: 
number of distinct artists:
number of distinct albums:
top 5 loudest songs:
top 5 longest songs:
top 5 fastest songs:
top 5 most familiar artists:
top 5 hottest songs:
top 5 hottest artists:
top 5 hottest genres (mean artists hotness in artist_term):
top 5 most popular keys (must have confidence > 0.7):
top 5 most prolific artists (include ex-equo items, if any):
top 5 most common words in song titles (excluding articles, prepositions, conjunctions):